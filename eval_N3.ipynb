{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiangpeiwen2/jiangpeiwen2/miniconda3/envs/n3/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from wayne_utils import load_data, save_data\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "from config import _ROOT_PATH, R3_ALL_METHODS\n",
    "from utils import Record_result, Check_result, split_merge\n",
    "from eval.R3.Syntax_Accuracy import SA_Batch\n",
    "from eval.R3.R3_Execute_Accuracy import R3_EA_Batch, R3_ExecuteAccuracy\n",
    "from eval.R3.Comprehension_Accuracy import CA_Batch\n",
    "from eval.R3.My_postprocess import post_execute_result\n",
    "from eval.R3.My_Execute_Accuracy import My_EA_Batch\n",
    "from eval.SpCQL.CA_Metric import Neo4j_ComprehensionAccuracy\n",
    "from eval.R3.My_Exact_Set_Match import ExactSetMatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allow_list = {\n",
    "    \"EM\": True,\n",
    "    \"SA\": True,\n",
    "    \"CA\": True,\n",
    "    \"R3_EA\": True,\n",
    "    \"EA\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FT\n",
      "FT-GLM4-9B\n",
      "FT-GLM4-9B的query list和exec result都存在，可以进行eval\n",
      "不存在记录FT-GLM4-9B-EM，允许重写。\n",
      "新的记录：FTGLM4-9B的EM = 16.34768740031898\n",
      "不存在记录FT-GLM4-9B-CA，允许重写。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiangpeiwen2/jiangpeiwen2/miniconda3/envs/n3/lib/python3.9/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Bert Scoring: 1254it [00:24, 50.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "新的记录：FTGLM4-9B的CA = 45.8207132116252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SA evaluating...: 100%|██████████| 1254/1254 [00:00<00:00, 1423067.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "不存在记录FT-GLM4-9B-SA，允许重写。\n",
      "新的记录：FTGLM4-9B的SA = 80.622009569378\n",
      "新的记录：FTGLM4-9B的ER = 20.015948963317385\n",
      "不存在记录FT-GLM4-9B-N3_EA，允许重写。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "N3 EA evaluating...:   0%|          | 0/1254 [00:00<?, ?it/s]/home/jiangpeiwen2/jiangpeiwen2/miniconda3/envs/n3/lib/python3.9/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "N3 EA evaluating...:   0%|          | 1/1254 [00:02<59:58,  2.87s/it]Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.569 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "N3 EA evaluating...: 100%|██████████| 1254/1254 [00:24<00:00, 51.94it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "新的记录：FTGLM4-9B的N3_EA = 55.57716479887038\n",
      "新的记录：FTGLM4-9B的N3_IEA = 68.93547443895496\n",
      "不存在记录FT-GLM4-9B-EA，允许重写。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "After evaluating: 100%|██████████| 1254/1254 [00:00<00:00, 5587.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "新的记录：FTGLM4-9B的EA = 39.473684210526315\n",
      "新的记录：FTGLM4-9B的EEA = 44.896331738437\n",
      "新的记录：FTGLM4-9B的IEA = 48.961424332344215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gold_query_list = load_data( os.path.join( _ROOT_PATH, \"data/R3/R3_gold_query_list.json\" ), \"json\")\n",
    "gold_result_list = load_data( os.path.join( _ROOT_PATH, \"data/R3/R3_gold_result_list.pickle\"), \"pickle\")\n",
    "for method in [\"FT\"]:          # [\"MyMethod\"]:      # R3_ALL_METHODS.keys(): #  #\n",
    "    print( method )\n",
    "    for sub_method in [\"GLM4-9B\"]:      # R3_ALL_METHODS[method].keys():  # [\"Chinese-Mistral-7B-Instruct-v0.1\"]:     #  \n",
    "        # if methods[method][sub_method]:\n",
    "        \n",
    "        whole_method_name = method +\"-\" + sub_method if sub_method != \"\" else method\n",
    "        sub_method = None if sub_method == \"\" else sub_method\n",
    "        print( whole_method_name )\n",
    "        \n",
    "        if method == \"Gold\":\n",
    "            predict_query_path = os.path.join( _ROOT_PATH, \"data/R3/R3_gold_query_list.json\" )\n",
    "            predict_result_path = os.path.join( _ROOT_PATH, \"data/R3/R3_gold_result_list.pickle\")\n",
    "        else:\n",
    "            predict_query_path = os.path.join( _ROOT_PATH, f\"inter_data/R3/query_list/{whole_method_name}_query_list.json\" )\n",
    "            predict_result_path = os.path.join( _ROOT_PATH, f\"inter_data/R3/execute_result_list/{whole_method_name}_execute_results.pickle\")\n",
    "        \n",
    "        if os.path.exists( predict_query_path ) and os.path.exists( predict_result_path ):\n",
    "            print( f\"{whole_method_name}的query list和exec result都存在，可以进行eval\")\n",
    "            \n",
    "            predict_query_list = load_data( predict_query_path, \"json\")\n",
    "            if isinstance(predict_query_list, dict):\n",
    "                predict_query_list, _ = split_merge( predict_query_list )\n",
    "            predict_result_list = load_data( predict_result_path, \"pickle\")\n",
    "            \n",
    "\n",
    "            if allow_list[ \"EM\" ] and Check_result( \"EM\", method, dataset = \"R3\", sub_method = sub_method, overwrite = False):\n",
    "                EM, EM_list = ExactSetMatch( gold_query_list, predict_query_list )\n",
    "                Record_result( \"EM\", EM, method, \"R3\", sub_method)\n",
    "            if allow_list[ \"CA\" ] and Check_result( \"CA\", method, dataset = \"R3\", sub_method = sub_method, overwrite = False):\n",
    "                # CA, CA_list = CA_Batch( predict_query_list, gold_query_list, model_type=\"roberta-large\")\n",
    "                CA = Neo4j_ComprehensionAccuracy( predict_query_list, gold_query_list)\n",
    "                Record_result( \"CA\", CA, method, \"R3\", sub_method)\n",
    "            \n",
    "            if allow_list[\"SA\"] or allow_list[\"R3_EA\"] or allow_list[\"EA\"]:\n",
    "                SA, SA_list, ER = SA_Batch( predict_result_list )                       # query语义错误\n",
    "            \n",
    "            if allow_list[ \"SA\" ] and Check_result( \"SA\", method, dataset = \"R3\", sub_method = sub_method, overwrite = False):\n",
    "                Record_result( \"SA\", SA, method, \"R3\", sub_method)\n",
    "                Record_result( \"ER\", ER, method, \"R3\", sub_method)\n",
    "\n",
    "            predict_result_list = post_execute_result( predict_result_list )\n",
    "            gold_result_list = post_execute_result( gold_result_list )\n",
    "            if allow_list[ \"R3_EA\" ] and Check_result( \"R3_EA\", method, dataset = \"R3\", sub_method = sub_method, overwrite = False):\n",
    "                R3_EA, R3_IEA = R3_EA_Batch( predict_result_list, gold_result_list, SA_list )\n",
    "                Record_result( \"R3_EA\", R3_EA, method, \"R3\", sub_method)\n",
    "                Record_result( \"R3_IEA\", R3_IEA, method, \"R3\", sub_method)\n",
    "            \n",
    "            if allow_list[ \"EA\" ] and Check_result( \"EA\", method,  dataset = \"R3\", sub_method = sub_method, overwrite = False):\n",
    "                EA, IEA, EEA, EA_list, EEA_list = My_EA_Batch( predict_result_list, gold_result_list, SA_list)     # 结果精确\n",
    "                Record_result( \"EA\", EA, method, \"R3\", sub_method)\n",
    "                Record_result( \"EEA\", EEA, method, \"R3\", sub_method)\n",
    "                Record_result( \"IEA\", IEA, method, \"R3\", sub_method)\n",
    "        else:\n",
    "            print( f\"路径不存在{predict_query_path}或者{predict_result_path}\")\n",
    "            \"\"\"\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "n3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

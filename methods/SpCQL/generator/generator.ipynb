{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wayne_utils import load_data, save_data\n",
    "import re\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "tests = load_data( \"/home/jiangpeiwen2/jiangpeiwen2/projects/SpCQL_db_process/test.json\", \"json\")       # 2007\n",
    "trains = load_data( \"/home/jiangpeiwen2/jiangpeiwen2/projects/SpCQL_db_process/train.json\", \"json\")     # 7001\n",
    "\n",
    "test_nl_list = [tests[i][\"query\"] for i in range(len(tests))]\n",
    "\n",
    "label_skeleton_list = load_data( \"/home/jiangpeiwen2/jiangpeiwen2/NL2GQL/methods/MyMethod/SpCQL/align_db/skeleton_list_label.json\", \"json\")\n",
    "predict_skeleton_list = load_data( \"/home/jiangpeiwen2/jiangpeiwen2/NL2GQL/methods/MyMethod/SpCQL/align_db/skeleton_list_predict.json\", \"json\")\n",
    "train_fake_list = load_data( \"/home/jiangpeiwen2/jiangpeiwen2/NL2GQL/methods/MyMethod/SpCQL/align_db/skeleton_list_train.json\", \"json\")\n",
    "train_true_list = [trains[i][\"cypher\"] for i in range(len(trains))]\n",
    "train_nl_list = [trains[i][\"query\"] for i in range(len(trains))]\n",
    "\n",
    "# ablation\n",
    "non_aligned_intention_skeleton_list = load_data( \"/home/jiangpeiwen2/jiangpeiwen2/NL2GQL/methods/MyMethod/SpCQL/ablation/non_aligned_intention_skeleton_list.json\", \"json\")\n",
    "\n",
    "non_skeleton_intention_train_list = load_data( \"/home/jiangpeiwen2/jiangpeiwen2/NL2GQL/methods/MyMethod/SpCQL/intentions/MyMethod_SpCQL_intention_trains_list.json\", \"json\")\n",
    "non_skeleton_intention_test_list = load_data( \"/home/jiangpeiwen2/jiangpeiwen2/NL2GQL/methods/MyMethod/SpCQL/align_db/intentions_aligned.json\", \"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Instruction = \"\"\"你是一名Neo4j数据库专家，精通Cypher查询语言。下面请你根据用户自然语言查询，结合意图识别结果组件生成的伪查询，生成正真的Cypher查询语句。\n",
    "自然语言查询部分是原始的用户自然语言表述的查询需求；正式查询部分是能够在Neo4j数据库中执行的语法严谨的Cypher语句。\n",
    "伪查询：对用户查询进行意图识别后得到的伪Cypher，里面包含了与数据库对齐的标签名和属性名，以及一些基本的Cypher组件。细节如下：\n",
    "（1）match子句是可能会使用的一些节点、关系、路径对象的列表，其中圆括号中是节点，方括号中是关系，列表中的顺序不代表Cypher语句中的顺序。此外，其中尚未包括最短路径、with子句、多个match并列、Union等复杂情况，如有需要你自行添加。\n",
    "（2）where子句中是一些可能会使用到的筛选条件。return子句后面是返回格式，已包括对返回格式的大概猜想。\n",
    "（3）三个部分中的变量名都没有正式命名，你需要结合语句重新将所有节点变量、关系变量、变量替换为英文字符代表的变量名（变量名不是必须的话可以不要），且确保前后一致性。\n",
    "（4）伪查询仅展示了可能的查询结构，作为你生成正式查询的参考。除非你觉得必要，你不要擅自重写属性名、属性值和标签，因为这是与数据库对齐后的结果。\n",
    "（5）此外，请你着重考虑关系、路径之间的方向连接、路径长度等要素，重视多查询对象和多返回结果的可能性，以及审查过滤条件和返回格式与自然语言要求的一致性。\n",
    "\"\"\"\n",
    "\n",
    "Input = \"\"\"自然语言查询：{NL}\n",
    "伪查询：{FAKE}\n",
    "正式查询：\"\"\"\n",
    "\n",
    "\n",
    "Instruction_NON_SKELETON = \"\"\"你是一名Neo4j数据库专家，精通Cypher查询语言。下面请你根据用户自然语言查询，结合意图识别结果，生成Cypher查询语句。\n",
    "自然语言查询部分是原始的用户自然语言表述的查询需求；正式查询部分是能够在Neo4j数据库中执行的语法严谨的Cypher语句。\n",
    "意图识别结果：对用户查询进行意图识别后得到的字典数据，里面包含了与数据库对齐的标签名和属性名，以及一些基本的Cypher组件。细节如下：\n",
    "（1）对象：可能会使用的一些节点、关系、路径对象的属性字典，其中待查询代表用户希望查询的属性值。\n",
    "（2）约束：包含可能在where子句中使用到的一些约束条件。\n",
    "（3）返回形式：包含可能在Cypher语句中使用的一些对返回值的要求，例如是否去重、聚合、排序、分页等。\n",
    "\"\"\"\n",
    "\n",
    "Input_NON_SKELETON = \"\"\"自然语言查询：{NL}\n",
    "用户意图：{FAKE}\n",
    "正式查询：\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator_prompt( nl_list, fake_lists, true_lists=None ):\n",
    "    if len(fake_lists) != len(nl_list):\n",
    "        raise Exception(f\"长度不一致{len(fake_lists), len(nl_list)}\")\n",
    "    ret_list = []\n",
    "    for i in range( len(nl_list) ):\n",
    "        nl = nl_list[i]\n",
    "        fake = fake_lists[i]\n",
    "        if true_lists == None:\n",
    "            ret_list.append( Instruction + Input.format(NL=nl, FAKE=fake ))\n",
    "        else:\n",
    "            ret_list.append( {\n",
    "                \"instruction\": Instruction,\n",
    "                \"input\": Input.format(NL=nl, FAKE=fake ),\n",
    "                \"output\": true_lists[i]\n",
    "            })\n",
    "    return ret_list\n",
    "\n",
    "'''train_ft_list = get_generator_prompt( train_nl_list, train_fake_list, true_lists=train_true_list )\n",
    "save_data( train_ft_list, \"MyMethod_SpCQL_generator_ft.json\")\n",
    "perfect_test_prompts_list = get_generator_prompt( test_nl_list, label_skeleton_list, true_lists=None )\n",
    "\n",
    "save_data( perfect_test_prompts_list, \"MyMethod-Perfect_prompt_list.pickle\")\n",
    "'''\n",
    "\n",
    "test_prompts_list = get_generator_prompt( test_nl_list, non_aligned_intention_skeleton_list, true_lists=None )\n",
    "save_data( test_prompts_list, \"MyMethod_SpCQL_generator_non_aligned_prompt_list.pickle\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator_prompt( nl_list, fake_lists, true_lists=None ):\n",
    "    if len(fake_lists) != len(nl_list):\n",
    "        raise Exception(f\"长度不一致{len(fake_lists), len(nl_list)}\")\n",
    "    ret_list = []\n",
    "    for i in range( len(nl_list) ):\n",
    "        nl = nl_list[i]\n",
    "        fake = fake_lists[i]\n",
    "        if true_lists == None:\n",
    "            ret_list.append( Instruction_NON_SKELETON + Input_NON_SKELETON.format(NL=nl, FAKE=fake ))\n",
    "        else:\n",
    "            ret_list.append( {\n",
    "                \"instruction\": Instruction_NON_SKELETON,\n",
    "                \"input\": Input_NON_SKELETON.format(NL=nl, FAKE=fake ),\n",
    "                \"output\": true_lists[i]\n",
    "            })\n",
    "    return ret_list\n",
    "\n",
    "'''微调数据集构建\n",
    "non_aligned_test_prompts_list = get_generator_prompt( train_nl_list, non_skeleton_intention_train_list, true_lists=train_true_list )\n",
    "save_data( non_aligned_test_prompts_list, \"MyMethod_SpCQL_generator_non_aligned_train_list.json\")'''\n",
    "\n",
    "non_aligned_test_prompts_list = get_generator_prompt( test_nl_list, non_skeleton_intention_test_list, true_lists=None )\n",
    "save_data( non_aligned_test_prompts_list, \"MyMethod_SpCQL_generator_non_skeleton_prompt_list.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# cypher子句与关键字字典\n",
    "cypher_clauses = {\n",
    "    \"MATCH\": \"用于在图中查找模式。\tMATCH (n:Person)-[:FRIEND]->(m)。包含节点、边、路径三类组成的模式，以及用逗号分隔的独立模式\", \n",
    "    \"OPTIONAL MATCH\": \"类似 MATCH，但允许模式不匹配，返回 NULL。\tOPTIONAL MATCH (n)-[:KNOWS]->(m)\", \n",
    "    \"WHERE\": \"为模式或结果添加过滤条件。\tMATCH (n) WHERE n.age > 30 RETURN n\", \n",
    "    \"RETURN\": \"指定查询结果的输出。\tRETURN n.name, n.age\", \n",
    "    \"WITH\": \"管道式传递中间结果，可用于聚合、过滤、或重命名。\tWITH n.name AS name MATCH (m:City)\", \n",
    "    \"UNWIND\": \"将列表展开为行。\tUNWIND [1, 2, 3] AS num RETURN num\", \n",
    "    \"CREATE\": \"创建节点、关系或子图。\tCREATE (n:Person {name: 'Alice'})\", \n",
    "    \"MERGE\": \"查找或创建节点或关系。\tMERGE (n:Person {name: 'Alice'})\", \n",
    "    \"SET\": \"更新节点或关系的属性或标签。\tSET n.age = 30, n:Adult\", \n",
    "    \"DELETE\": \"删除节点、关系或子图。\tMATCH (n) DELETE n\", \n",
    "    \"REMOVE\": \"移除节点或关系的标签或属性。\tMATCH (n) REMOVE n.age\", \n",
    "    \"FOREACH\": \"针对列表中的每个元素执行一段写操作。\t`FOREACH (x IN range(1,10)\", \n",
    "    \"CALL\": \"调用存储过程或自定义函数。\tCALL dbms.procedures()\", \n",
    "    \"LOAD CSV\": \"导入 CSV 文件中的数据。\tLOAD CSV FROM 'file:///data.csv' AS row\", \n",
    "    \"START\": \"基于图数据库索引查询，主要用于旧版。\tSTART n=node(1) RETURN n\", \n",
    "    \"ORDER BY\": \"指定查询结果的排序顺序。\tRETURN n ORDER BY n.name DESC\", \n",
    "    \"SKIP\": \"跳过指定数量的行。\tRETURN n SKIP 10\", \n",
    "    \"LIMIT\": \"限制返回的结果行数。\tRETURN n LIMIT 5\", \n",
    "    \"UNION\": \"合并两个查询的结果集（去重）。\tMATCH (a:Person) RETURN a.name UNION ...\", \n",
    "    \"UNION ALL\": \"合并两个查询的结果集（不去重）。\tMATCH (a:Person) RETURN a.name UNION ALL\", \n",
    "}\n",
    "\n",
    "def split_cypher_clauses(query: str) -> dict:\n",
    "    clause_pattern = re.compile(\n",
    "        r\"\\b(\" + r\"|\".join(re.escape(clause.lower()) for clause in cypher_clauses) + r\")\\b\"\n",
    "    )\n",
    "    matches = list(clause_pattern.finditer(query))\n",
    "    if not matches:\n",
    "        return {}\n",
    "    result = OrderedDict({})\n",
    "    for i, match in enumerate(matches):\n",
    "        clause = match.group(1)\n",
    "        start = match.end()\n",
    "        end = matches[i + 1].start() if i + 1 < len(matches) else len(query)\n",
    "        result[clause] = query[start:end].strip()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('match',\n",
       "              \"(:ENTITY{name:'闻香蚀骨'})-[:Relationship{name:'连载平台'}]->(r)\"),\n",
       "             ('return', 'r.name as name'),\n",
       "             ('union', 'all')])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_cypher_clauses( \"match (:ENTITY{name:'闻香蚀骨'})-[:Relationship{name:'作者'}]->(n) return n.name as name union all match (:ENTITY{name:'闻香蚀骨'})-[:Relationship{name:'类型'}]->(m) return m.name as name union all match (:ENTITY{name:'闻香蚀骨'})-[:Relationship{name:'连载平台'}]->(r) return r.name as name\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t2c",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
